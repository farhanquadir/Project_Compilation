import numpy as np
import pandas as pd
from sklearn.mixture import GaussianMixture
import math

X_train = np.loadtxt('GMD_Train.dat')
X_valid = np.loadtxt('GMD_Valid.dat')

def n_parameters(gmm):
    """Return the number of free parameters in the model."""
    _, n_features = gmm.means_.shape
    if gmm.covariance_type == 'full':
        cov_params = gmm.n_components * n_features * (n_features + 1) / 2.
    elif gmm.covariance_type == 'diag':
        cov_params = gmm.n_components * n_features
    elif gmm.covariance_type == 'tied':
        cov_params = n_features * (n_features + 1) / 2.
    elif gmm.covariance_type == 'spherical':
        cov_params = gmm.n_components
    mean_params = n_features * gmm.n_components
    return int(cov_params + mean_params + gmm.n_components - 1)

for K in range(1, 5):

    cov_types = ['spherical', 'diag', 'full']

    for cur_cov in cov_types:
        mean_init = np.array([
        [13, 1, 6, 5],
        [4, 0, 8, 6]])
        mean_init = mean_init.T
        mean_init = mean_init[0:K, :]
        weight_init = np.ones(K)
        for i in range(0, K):
            weight_init[i] = 1.0/K
        
        gmm = GaussianMixture(n_components=K, covariance_type=cur_cov, max_iter=20, \
            means_init=mean_init, weights_init=weight_init, tol=1e-20)
        gmm.fit(X_train)

        print('K = {}, BIC for {}, score = {}\nnum_params = {}, BIC = {}'.format(K, cur_cov, gmm.score(X_valid) * np.size(X_valid, 0), \
             n_parameters(gmm), gmm.bic(X_valid)))
        N = np.size(X_valid, 0)
        my_bic = (-2 * gmm.score(X_valid) * N) + (n_parameters(gmm) * np.log(N))
        print('iter = {}, my-BIC = {}'.format(gmm.n_iter_, my_bic))
    pass
pass

