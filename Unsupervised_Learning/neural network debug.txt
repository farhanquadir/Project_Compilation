The following recommendations are mainly for beginners of neural networks, which are based on my experience for industry and Stanford's newcomers to neural networks. Neural networks are basically harder to debug than most programs because most neural network errors do not cause type errors or runtime errors. They just cause the neural network to be difficult to converge. Especially when you are new to this, it may make you very depressed! But an experienced neural network trainer will be able to systematically overcome these difficulties, despite the existence of a large number of plausible error messages: performance errors: your neural network is not well trained. For people with inexperience, this information is daunting. But for experienced, this is a very good error message. This means that the sample code has deviated from the right path, it is time to dig deeper for the reason!

How to deal with NaN
The most common first question I have received from students so far is, "Why did I have NaNs?". Sometimes the answer to this question is complicated. But most of the time, NaNs appeared in the first 100 iterations, and the answer is very simple: your learning rate is set too high. When the learning rate is very high, NaNs appear in the first 100 iterations of training. Try to continuously divide the learning rate by 3 until NaNs no longer appear in the first 100 iterations. Once this works, you get a good initial learning rate. According to my experience, the best effective learning rate is generally less than 1-10 times the learning rate of NaNs.
If you are a NaNs that appears after more than 100 iterations, there are 2 other common reasons. 
1) If you are training RNN, be sure to use "clip gradient", which limits the global gradient two norm (L2) to a certain range. RNN tends to produce gradients early in the training, where 10% or less of the patches will have learning spikes, and the gradients on these spikes are very large. If there is no limit, these spikes can lead to NaNs. 
2) If you have written any custom layers yourself, then the problem is most likely caused by some divide-by-zero errors in these custom layers. Another well-known layer that produces NaNs is the softmax layer. The calculation of softmax contains the exponential function exp(x) in both the numerator and the denominator. When inf is divided by inf, NaNs may be generated. So make sure you are using a stable version of the softmax implementation.

What to do when the neural network is no longer learning
When you no longer encounter NaNs, you are likely to encounter a situation where your network has been trained for thousands of rounds, but the loss value of the training is no longer reduced after the first few hundred rounds. If you are building a code base for the first time, you basically won't say you need to wait for more than 2000 iterations. This is not because all networks can start learning in 2000 iterations, but because you have a high probability of introducing bugs in coding, rather than waiting for a long iteration, it is better to enter debug mode early. Now you should keep narrowing the scope of the problem until your network can start learning in 2000 iterations. Fortunately, there are 2 nice dimensions to reduce complexity:

1) Reduce the sample size of the training set to 10. Any available network can usually fit ten samples after hundreds of iterations. But a lot of coding bugs will prevent this from happening. If your network still can't over-fitting the 10 samples of the training set, please double check that the data and labels are correct. Try setting the batch size to 1 to check for errors in the batch calculation. Add some log output to your code to make sure it works the way you want it to. In general, these errors are always found through violent investigations. Once the network can fit 10 samples, continue to try to fit 100. If you can train normally now but not as expected, you can move on to the next step.

2) The simplest version of the problem you are interested in. If you are doing a sentence translation, try to build a language model for the target language first. When the previous step is successful, only the words in the three source languages ​​are given, and try to predict the first word of the translation. If you plan to detect objects from an image, try to categorize how many objects are in the image before training the regression network. There is a trade-off between getting a good sub-problem that the network can solve, and spending the least amount of time to use the code to hook up the data. Creativity can help.

The trick to extending the network for a new idea is to slowly reduce the simplifications made in the two steps above. This is a form of coordinate rise and is very useful. In the beginning, you can prove that the network can remember a small number of samples, and then you can prove that it can be generalized on the validation set in a simplified version of the subproblem. Gradually increase the difficulty and move forward steadily. This is not as interesting as the first Karpathy style, but at least it is useful. Sometimes you will find that some problems are very difficult in itself and it is difficult to complete the study in 2000 iterations. it's great! But it rarely needs more than ten times the number of iterations of the previous difficulty level problem. If you really need so many iterations, try to find an intermediate complexity.
Adjusting hyperparameters
Since your network is starting to learn now, you may feel good. But you may find that it does not solve the most difficult version of this problem. The adjustment of hyperparameters is the key. Maybe someone just downloaded a CNN package and ran his own data set on it, and told you that the adjustment of the hyper-parameter does not change. You have to realize that they are using existing frameworks to solve existing problems. If you are using a new architecture to solve new problems, you must debug the hyperparameters to get a good configuration. You'd better read a super-parameter tutorial for your specific problem, but for completeness I'll list some basic ideas here:


Visualization is the key. Don't be afraid to spend time writing some useful visualization tools throughout the training process. If your visualization method is simply to observe changes in the loss value in the terminal, then you should consider upgrading.

Weight initialization is important. In general, a larger initial weight will be better, but too large will lead to NaN. Therefore, the initial weight needs to be adjusted along with the learning rate.

Make sure the weights look "healthy." To understand what this means, I recommend using ipython notebook to open the weight of an existing network. Take some time to familiarize yourself with what the weight histogram of components in a mature network trained on a standard dataset (such as ImageNet or Penn Tree Bank) should look like.

The neural network is not invariant to the input scale, especially when it uses SGD training instead of other second-order methods because SGD is not a scale-invariant method. Take a moment to try to scale the input data and output labels multiple times before determining the scaling scale.

Reducing the learning rate before the end of training can always lead to improvement. The best decay strategy is: after k epochs, divide the learning rate by 1.5 after every n epochs, where k > n.

Use a hyperparameter configuration file. Although it is ok to put hyperparameters in the code before you start trying different values. I use the json file by command line parameter loading, just like in Russell91/TensorBox, but the specific form is not important. Avoid always refactoring your code, because that would be a bad problem with hyperparameter loading. Refactoring introduces bugs and spends your training cycle, which can be avoided until you have a network that you feel good about.

Randomly search for hyperparameters, if you can. Random search can produce a combination of hyperparameters that you can't think of, and can reduce the amount of work you have once trained to form an intuition that affects a given hyperparameter.

to sum up
Debugging a neural network can be more labor-intensive than debugging a traditional program, because almost all errors are projected into a single dimension of the entire network performance. Still, binary search still works. By alternating 1) the difficulty of adjusting the problem, and 2) using a small number of training samples, you can quickly solve the initial problem. Then super-parameter adjustments and long waits can solve your remaining problems.

Author: zhwhong
Link: https://www.jianshu.com/p/ba2ac29810e6
Source: Short book
The copyright of the book is owned by the author. Any form of reprint should be contacted by the author for authorization and the source.